<!--
Web Camera Person Detector + Pose Skeleton
Single-file demo using TensorFlow.js
- Person detection: coco-ssd
- Pose estimation: MoveNet (via @tensorflow-models/pose-detection)

Instructions:
1) Serve this file via a local server (live-server, python -m http.server, or upload to GitHub Pages).
   Opening file:// may block camera permissions.
2) Allow camera access. The app uses rear camera if available on mobile.
3) For performance, use a modern device and allow WebGL.

You can split CSS/JS into separate files if you prefer.
--><!doctype html>

<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1.0" />
  <title>Detector de Personas + Pose</title>  <!-- Libraries (CDN) -->  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.11.0/dist/tf.min.js"></script>  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2/dist/coco-ssd.min.js"></script>  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@0.0.8/dist/pose-detection.min.js"></script>  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@0.0.8/dist/movenet.min.js"></script>  <!-- Simple CSS (you can extract to a separate .css file) -->  <style>
    :root{font-family:Inter, system-ui, -apple-system, 'Segoe UI', Roboto, 'Helvetica Neue', Arial;}
    body{margin:0;background:#0b1020;color:#e6eef8;display:flex;flex-direction:column;height:100vh}
    header{padding:10px 14px;background:#081025;display:flex;align-items:center;gap:12px}
    h1{font-size:16px;margin:0}
    #container{flex:1;position:relative;display:flex;align-items:center;justify-content:center}
    video, canvas{max-width:100%;height:auto;border-radius:8px}
    video{transform:scaleX(-1)} /* mirror for user-friendly view */

    #controls{position:absolute;left:12px;top:12px;display:flex;gap:8px;flex-wrap:wrap}
    .btn{background:rgba(255,255,255,0.06);border:1px solid rgba(255,255,255,0.06);padding:8px 10px;border-radius:8px;color:#dfe9ff;cursor:pointer}
    .btn:active{transform:translateY(1px)}

    footer{padding:8px 12px;font-size:13px;background:#06101b;color:#9fb0d6}
    .badge{background:#1c7a1c;padding:4px 8px;border-radius:6px;font-weight:600}

    /* small screen tweaks */
    @media (max-width:700px){header h1{font-size:14px}}
  </style></head>
<body>
  <header>
    <h1>Detector de Personas + Pose — abre la consola para logs</h1>
    <div style="margin-left:auto;display:flex;gap:8px;align-items:center">
      <div class="badge">Modo demo</div>
    </div>
  </header>  <main id="container">
    <!-- Video element (camera) -->
    <video id="video" playsinline autoplay muted></video>
    <!-- Canvas overlay where we draw boxes & skeleton -->
    <canvas id="overlay"></canvas><div id="controls">
  <button id="startBtn" class="btn">Iniciar</button>
  <button id="stopBtn" class="btn">Detener</button>
  <button id="toggleMirror" class="btn">Espejo: ON</button>
  <label class="btn" style="display:flex;align-items:center;gap:6px"><input id="showBoxes" type="checkbox" checked> Boxes</label>
  <label class="btn" style="display:flex;align-items:center;gap:6px"><input id="showPose" type="checkbox" checked> Pose</label>
  <select id="quality" class="btn">
    <option value="high">Alta</option>
    <option value="medium" selected>Media</option>
    <option value="low">Baja</option>
  </select>
</div>

  </main>  <footer>
    · Usa un servidor local (python -m http.server 8000 o live-server) · Recomendado: Chrome/Edge ·
  </footer>  <!-- App logic (you can extract to main.js) -->  <script>
    // Element refs
    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const toggleMirrorBtn = document.getElementById('toggleMirror');
    const showBoxesCheckbox = document.getElementById('showBoxes');
    const showPoseCheckbox = document.getElementById('showPose');
    const qualitySelect = document.getElementById('quality');

    let streaming = false;
    let cocoModel = null;
    let poseDetector = null;
    let rafId = null;
    let videoWidth = 640;
    let videoHeight = 480;
    let mirrored = true;

    // Utility: resize canvas to match video
    function resizeCanvasToVideo() {
      overlay.width = video.videoWidth;
      overlay.height = video.videoHeight;
      overlay.style.width = video.offsetWidth + 'px';
      overlay.style.height = video.offsetHeight + 'px';
    }

    async function initCamera() {
      // choose resolution based on quality
      const quality = qualitySelect.value;
      let constraints = { audio:false, video:{ facingMode: 'user'} };
      if (quality === 'high') constraints.video.width = { ideal:1280 }, constraints.video.height = { ideal:720 };
      if (quality === 'medium') constraints.video.width = { ideal:640 }, constraints.video.height = { ideal:480 };
      if (quality === 'low') constraints.video.width = { ideal:320 }, constraints.video.height = { ideal:240 };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      video.srcObject = stream;

      return new Promise((res) => {
        video.onloadedmetadata = () => {
          video.play();
          resizeCanvasToVideo();
          res();
        };
      });
    }

    async function loadModels() {
      console.log('Cargando coco-ssd...');
      cocoModel = await cocoSsd.load();
      console.log('coco-ssd cargado');

      console.log('Cargando MoveNet...');
      // create MoveNet detector
      const detectorConfig = {modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING};
      poseDetector = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet, detectorConfig);
      console.log('MoveNet cargado');
    }

    function drawDetections(ctx, detections) {
      ctx.lineWidth = Math.max(2, Math.round(overlay.height / 240));
      ctx.strokeStyle = 'rgba(0,220,0,1)';
      ctx.fillStyle = 'rgba(0,220,0,0.2)';
      ctx.font = `${12}px Arial`;

      detections.forEach(det => {
        if (det.class === 'person' && det.score > 0.45) {
          const [x,y,w,h] = det.bbox; // x,y,w,h
          ctx.beginPath();
          ctx.rect(x,y,w,h);
          ctx.stroke();
          ctx.fillRect(x,y,w,Math.min(18, overlay.height*0.04));
          ctx.fillStyle = 'rgba(0,0,0,0.6)';
          ctx.fillText(`${det.class} ${(det.score*100).toFixed(0)}%`, x+4, y+12);
          ctx.fillStyle = 'rgba(0,220,0,0.2)';
        }
      });
    }

    function drawPose(ctx, pose) {
      if (!pose || !pose.keypoints) return;
      const keypoints = pose.keypoints;
      // draw skeleton lines for common connections
      const connections = [
        ['left_shoulder','right_shoulder'],
        ['left_shoulder','left_elbow'], ['left_elbow','left_wrist'],
        ['right_shoulder','right_elbow'], ['right_elbow','right_wrist'],
        ['left_shoulder','left_hip'], ['right_shoulder','right_hip'],
        ['left_hip','right_hip'],
        ['left_hip','left_knee'], ['left_knee','left_ankle'],
        ['right_hip','right_knee'], ['right_knee','right_ankle']
      ];

      ctx.lineWidth = Math.max(2, Math.round(overlay.height / 250));
      ctx.strokeStyle = 'rgba(0,255,0,0.95)';
      ctx.fillStyle = 'rgba(0,255,0,0.9)';

      // helper to get keypoint by name
      const kpByName = {};
      keypoints.forEach(kp=> kpByName[kp.name || kp.part] = kp);

      // draw connections
      connections.forEach(([a,b])=>{
        const kpa = kpByName[a];
        const kpb = kpByName[b];
        if (!kpa || !kpb) return;
        if (kpa.score < 0.3 || kpb.score < 0.3) return;
        ctx.beginPath();
        ctx.moveTo(kpa.x, kpa.y);
        ctx.lineTo(kpb.x, kpb.y);
        ctx.stroke();
      });

      // draw keypoints
      keypoints.forEach(kp=>{
        if (kp.score < 0.25) return;
        ctx.beginPath();
        ctx.arc(kp.x, kp.y, Math.max(3, overlay.width/200), 0, Math.PI*2);
        ctx.fill();
      });
    }

    async function renderLoop() {
      if (!streaming) return;

      resizeCanvasToVideo();
      const ctx = overlay.getContext('2d');
      // clear
      ctx.clearRect(0,0,overlay.width,overlay.height);

      // flip canvas if mirrored
      ctx.save();
      if (mirrored) {
        ctx.scale(-1,1);
        ctx.translate(-overlay.width,0);
      }

      try {
        // run object detection (coco-ssd)
        if (cocoModel && showBoxesCheckbox.checked) {
          // input can be video element
          const predictions = await cocoModel.detect(video, 5);
          drawDetections(ctx, predictions);
        }

        // run pose detection
        if (poseDetector && showPoseCheckbox.checked) {
          const poses = await poseDetector.estimatePoses(video, {flipHorizontal: mirrored});
          // poses is an array; draw top one
          if (poses && poses.length>0) drawPose(ctx, poses[0]);
        }
      } catch (err) {
        console.error('Error en detección:', err);
      }

      ctx.restore();

      // schedule next frame
      rafId = requestAnimationFrame(renderLoop);
    }

    async function startApp() {
      if (streaming) return;
      await initCamera();
      await loadModels();
      streaming = true;
      renderLoop();
    }

    function stopApp() {
      streaming = false;
      if (rafId) cancelAnimationFrame(rafId);
      // stop camera tracks
      const stream = video.srcObject;
      if (stream) {
        stream.getTracks().forEach(t=>t.stop());
        video.srcObject = null;
      }
      const ctx = overlay.getContext('2d');
      ctx.clearRect(0,0,overlay.width,overlay.height);
    }

    // Event listeners
    startBtn.addEventListener('click', ()=> startApp());
    stopBtn.addEventListener('click', ()=> stopApp());
    toggleMirrorBtn.addEventListener('click', ()=>{
      mirrored = !mirrored;
      video.style.transform = mirrored ? 'scaleX(-1)' : 'scaleX(1)';
      toggleMirrorBtn.textContent = `Espejo: ${mirrored? 'ON':'OFF'}`;
    });

    // auto-start on page load
    (async ()=>{
      // optional: try to load camera eagerly but wait user to press start for models
      try {
        await initCamera();
        // pause video until user starts models to save cpu
        video.pause();
      } catch (e) {
        console.warn('No se pudo iniciar cámara automáticamente, presiona Iniciar:', e);
      }
    })();

    // clean up on unload
    window.addEventListener('beforeunload', stopApp);
  </script></body>
</html>
